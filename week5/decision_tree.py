# -*- coding: utf-8 -*-
"""Decision_Tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wsi-su1UcdPhn0G2A91KPwhBQnZDFkLh

# 1 - Load the dataset

We will use the dataset called "California Housing" from sklearn library to demonstration an implementation of a Decision Tree. This dataset has 20640 samples with 8 features (columns). Here target variable is the price of the house.
"""

#import the libs
from sklearn.datasets import fetch_california_housing
#load the dataset
house_data = fetch_california_housing()  #returns dictionary-like object, attributes are - data, target, DESCR
#first of all, let's see the shape of the training data
print(house_data.data.shape)

#shape of a target/labels
print(house_data.target.shape)

#important info about the dataset
print(house_data.DESCR)

import numpy as np       # Import numpy to use the numpy arrays, the structure of those arrays is designed to be optimal for calculations

X = house_data.data      # features of each house
X = np.array(X)
prices = house_data.target    # price of each house
y = [1 if price > 2 else 0 for price in prices]   # 1 is high house price, 0 is low house price
y = np.array(y)

print('Input features: ', ', '.join(house_data.feature_names))
print(X.shape)

"""Meaning of each feature:
* MedInc: median income in block group
* HouseAge: median house age in block group
* AveRooms: average number of rooms per household
* AveBedrms: average number of bedrooms per household
* Population: block group population
* AveOccup: average number of household members
* Latitude: block group latitude
* Longitude: block group longitude

These features contribute when evaluating prices of houses.

y = 1 when the house price is greater than 200,000 USD, otherwise y = 0.

# Build Decision Tree model and train it
"""

from sklearn.tree import DecisionTreeClassifier     # import the Decision Tree model
tree_clf = DecisionTreeClassifier(max_depth=3)      # Limit the depth of the tree to prevent overfitting
tree_clf.fit(X, y)                                  # Fit data and their label to train the model

"""# Visualise the Decision Tree

We use function export_graphviz() to visualise the Decision Tree. In this function, we just need to pass the trained Decision Tree model, feature names, and labels via the parameter "class_names"
"""

import graphviz
from sklearn import tree

dot_data = tree.export_graphviz(tree_clf, out_file = None, 
                                feature_names = house_data.feature_names,  
                                class_names = ['low', 'high'],
                                rounded = True,
                                filled = True)

graph = graphviz.Source(dot_data, format="png")
graph

"""# Test the Decisicion Tree

We will test the trained Decision Tree against the value of the first sample in the dataset (X[0]) and see if our Decision Tree can predict the correct label (0 or 1) for this sample.
"""

import pandas as pd

x = X[0].reshape(1, -1)     # Reshape to 2D array, because the function predict_proba() requires the parameter in 2D array
print("The true price of this house is: {:,} USD".format(prices[0] * 100000))
y_pred = tree_clf.predict_proba(x)
print("The probabilities generated by our Decision Tree are:")
print('Probability y = 0 (low price): {}'.format(y_pred[0][0]))
print('Probability y = 1 (high price): {}'.format(y_pred[0][1]))
print('Predicted label {}'.format(tree_clf.predict(x)[0]))
print('(1 means high price (> 200,000 USD), 0 means low price (<= 200,000 USD))')

